{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest,chi2 \n",
    "from sklearn import svm \n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,MaxAbsScaler,RobustScaler\n",
    "from sklearn.model_selection import train_test_split,KFold,GridSearchCV,cross_val_score,StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer,confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import os\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "!ls\n",
    "filenames=[]\n",
    "for i in os.listdir(\"Data/\"):\n",
    "    if len(i.strip('.csv'))==7:\n",
    "        filenames.append(\"Data/\"+i)\n",
    "data = pd.read_csv(filenames[0])\n",
    "# count number of 0 and 1 in the dataset\n",
    "data[\"categorize\"].value_counts()\n",
    "2694/(2694+11369)\n",
    "samples=[]\n",
    "for i in os.listdir(\"Data/\"):\n",
    "    if len(i.strip(\".csv\"))==7:\n",
    "        samples.append(i)\n",
    "samples\n",
    "file_sizes_blood = [1121212121,\n",
    " 2303030303,\n",
    " 1333333333,\n",
    " 1303030303,\n",
    " 1090909090,\n",
    " 803030303,\n",
    " 1242424242,\n",
    " 1469696969,\n",
    " 1363636363,\n",
    " 1348484848,\n",
    " 1227272727,\n",
    " 1272727272,\n",
    " 1257575757,\n",
    " 1015151515,\n",
    " 1136363636,\n",
    " 1666666666,\n",
    " 1363636363,\n",
    " 1439393939,\n",
    " 1015151515]\n",
    "for i in samples:\n",
    "    print(i+\" \")\n",
    "filenames\n",
    "len(filenames)\n",
    "# make a pooled dataset merge with start,end,chr and average categorize\n",
    "data = pd.read_csv(filenames[0])\n",
    "for file in filenames[1:15]:\n",
    "    data = pd.concat([data,pd.read_csv(file)])\n",
    "data = data.drop(columns=[\"Unnamed: 0\"])\n",
    "data = data.groupby([\"start\",\"end\",\"chr\"]).mean().reset_index()\n",
    "data.to_csv(\"Data/FinalFile_15_datasets_mean.csv\")\n",
    "\n",
    "# make a pooled dataset merge with start,end,chr and average categorize\n",
    "data = pd.read_csv(filenames[0])\n",
    "for file in filenames[1:5]:\n",
    "    data = pd.concat([data,pd.read_csv(file)])\n",
    "data = data.drop(columns=[\"Unnamed: 0\"])\n",
    "data = data.groupby([\"start\",\"end\",\"chr\"]).mean().reset_index()\n",
    "data.to_csv(\"Data/FinalFile_5_datasets_mean.csv\")\n",
    "\n",
    "def take_data_preprocess(filename,col=\"categorize\"):\n",
    "    x=pd.read_csv(filename)\n",
    "    y=np.array(x[col])\n",
    "    x=x.drop([\"Unnamed: 0\"],axis=1)\n",
    "    y=np.array(y).reshape(len(y)  ,)\n",
    "    y_1=np.where(y==0)[0]\n",
    "    y_2=np.where(y==1)[0]\n",
    "    index=np.random.choice(y_1,len(y_2), replace=False)\n",
    "    index=np.concatenate((index, y_2), axis=0)\n",
    "    x_32=x[[ 'AA_x', 'AT_x', 'AG_x', 'AC_x',\n",
    "       'TA_x', 'TT_x', 'TG_x', 'TC_x', 'GA_x', 'GT_x', 'GG_x', 'GC_x', 'CA_x',\n",
    "       'CT_x', 'CG_x', 'CC_x', 'AA_y', 'AT_y', 'AG_y', 'AC_y', 'TA_y', 'TT_y',\n",
    "       'TG_y', 'TC_y', 'GA_y', 'GT_y', 'GG_y', 'GC_y', 'CA_y', 'CT_y', 'CG_y',\n",
    "       'CC_y']]\n",
    "    x_32_norm=np.array(normalize(np.array(x_32)))\n",
    "    x, y = shuffle(x_32_norm[index], y[index], random_state=0)\n",
    "    return x,y\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    originalclass.extend(y_true)\n",
    "    predictedclass.extend(y_pred)\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score\n",
    "def classification_report_with_f1_score(y_true, y_pred):\n",
    "    originalclass.extend(y_true)\n",
    "    predictedclass.extend(y_pred)\n",
    "    return f1_score(y_true, y_pred,average='weighted') # return accuracy score\n",
    "def confidence_score(y_true,y_pred_prob):\n",
    "\n",
    "    keys=[0,1]\n",
    "    dict={}\n",
    "    i=0\n",
    "    for key in keys:\n",
    "        dict[key]=i\n",
    "        i+=1\n",
    "\n",
    "    cs=0.0\n",
    "    for i in range(len(y_true)):\n",
    "        cs+=y_pred_prob[i][dict[y_true[i]]]\n",
    "\n",
    "\n",
    "    return cs/len(y_true)\n",
    "def normalize(x):\n",
    "    new_x=[]\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        x_new=[]\n",
    "        for j in range(16,32):\n",
    "            a=np.sum(x[i][1:17])\n",
    "            b=np.sum(x[i][17:33])\n",
    "            x_new.append(x[i][j]*a/(0.01+ x[i][j-16]*b))\n",
    "        new_x.append(x_new)\n",
    "    return new_x\n",
    "accuracy_blood=[]\n",
    "for filename in filenames:\n",
    "    x,y=take_data_preprocess(filename)\n",
    "    x=StandardScaler().fit_transform(x)\n",
    "    \n",
    "    clf = RandomForestClassifier(class_weight='balanced', max_depth=20 ,n_estimators=800, criterion='entropy')\n",
    "    \n",
    "    originalclass = []\n",
    "    predictedclass = []\n",
    "\n",
    "    outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "    nested_score = cross_val_score(clf, X=x, y=y, cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    \n",
    "    accuracy_blood.append(sk.metrics.accuracy_score(originalclass, predictedclass))\n",
    "    \n",
    "    print(classification_report(originalclass, predictedclass))\n",
    "accuracy_blood\n",
    "np.mean(accuracy_blood),np.max(accuracy_blood),np.min(accuracy_blood)\n",
    "filenames=[]\n",
    "samples=[]\n",
    "for i in os.listdir(\"Data/\"):\n",
    "    if len(i.strip(\".csv\"))==10 and i!=\"SRR8670684\":\n",
    "        filenames.append(\"Data/\"+i)\n",
    "        data = pd.read_csv(\"Data/\"+i)\n",
    "        samples.append(data.columns[4])\n",
    "filenames, samples\n",
    "accuracy_blood_pooled=[]\n",
    "filenames_pooled = [\"Data/FinalFile_5_datasets_mean.csv\", \"Data/FinalFile_10_datasets_mean.csv\", \"Data/FinalFile_15_datasets_mean.csv\", \"Data/FinalFile_20_datasets_mean.csv\"]\n",
    "for filename in filenames_pooled:\n",
    "    x,y=take_data_preprocess(filename)\n",
    "    x=StandardScaler().fit_transform(x)\n",
    "    \n",
    "    clf = RandomForestClassifier(class_weight='balanced', max_depth=20 ,n_estimators=800, criterion='entropy')\n",
    "    \n",
    "    originalclass = []\n",
    "    predictedclass = []\n",
    "\n",
    "    outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "    nested_score = cross_val_score(clf, X=x, y=y, cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    \n",
    "    accuracy_blood_pooled.append(sk.metrics.accuracy_score(originalclass, predictedclass))\n",
    "    \n",
    "    print(classification_report(originalclass, predictedclass))\n",
    "filename\n",
    "ceph_files = os.listdir(\"/project/ReadStatistics-data/CEPH_BAM/\")[:50]\n",
    "# open each file directory and get the FinalFile.csv\n",
    "data = pd.read_csv(\"/project/ReadStatistics-data/CEPH_BAM/\"+ceph_files[0]+\"/FinalFile.csv\")\n",
    "print(data.columns)\n",
    "for file in ceph_files[1:]:\n",
    "    filename = \"/project/ReadStatistics-data/CEPH_BAM/\"+file+\"/FinalFile.csv\"\n",
    "    if os.path.exists(filename):\n",
    "        data = pd.concat([data,pd.read_csv(filename)])\n",
    "data\n",
    "import os\n",
    "\n",
    "data = data.groupby([\"start\",\"end\",\"chr\"]).mean().reset_index()\n",
    "data.to_csv(\"Data/FinalFile_50_ceph_datasets_mean.csv\")\n",
    "\n",
    "accuracy_ceph=[]\n",
    "filename = \"Data/FinalFile_50_ceph_datasets_mean.csv\"\n",
    "x,y=take_data_preprocess(filename)\n",
    "x=StandardScaler().fit_transform(x)\n",
    "\n",
    "clf = RandomForestClassifier(class_weight='balanced', max_depth=20 ,n_estimators=800, criterion='entropy')\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "nested_score = cross_val_score(clf, X=x, y=y, cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "\n",
    "accuracy_ceph.append(sk.metrics.accuracy_score(originalclass, predictedclass))\n",
    "\n",
    "print(classification_report(originalclass, predictedclass))\n",
    "\n",
    "accuracy_blood_pooled_race=[]\n",
    "filenames_pooled = [\"Data/FinalFile_5_datasets_mean.csv\", \"Data/FinalFile_10_datasets_mean.csv\", \"Data/FinalFile_15_datasets_mean.csv\", \"Data/FinalFile_20_datasets_mean.csv\"]\n",
    "for filename in filenames_pooled:\n",
    "    x,y=take_data_preprocess(filename)\n",
    "    x=StandardScaler().fit_transform(x)\n",
    "    \n",
    "    clf = RandomForestClassifier(class_weight='balanced', max_depth=20 ,n_estimators=800, criterion='entropy')\n",
    "    \n",
    "    originalclass = []\n",
    "    predictedclass = []\n",
    "\n",
    "    outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "    nested_score = cross_val_score(clf, X=x, y=y, cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    \n",
    "    accuracy_blood_pooled.append(sk.metrics.accuracy_score(originalclass, predictedclass))\n",
    "    \n",
    "    print(classification_report(originalclass, predictedclass))\n",
    "np.savez(\"Figures/accuracy_blood_pooled_data.npz\",accuracy_blood_pooled)\n",
    "cancer_types = samples \n",
    "file_sizes=[1303041736,\n",
    "1205710255,\n",
    "1696808001,\n",
    "1183872482,\n",
    "1259117801,\n",
    "1301672928,\n",
    "1177541886,\n",
    "1229410952,           \n",
    "979656179]\n",
    "def plot_roc_curves(model,train_x,train_y,test_x,test_y):\n",
    "    \n",
    "    model_dummy = DummyClassifier(strategy='stratified')\n",
    "    model_dummy.fit(train_x, train_y)\n",
    "    yhat = model_dummy.predict_proba(test_x)\n",
    "    naive_probs = yhat[:, 1]\n",
    "\n",
    "\n",
    "    yhat = model.predict_proba(test_x)\n",
    "    pos_probs = yhat[:, 1]\n",
    "    roc_auc = roc_auc_score(test_y, pos_probs)\n",
    "    fpr, tpr, thresholds = sk.metrics.roc_curve(test_y, pos_probs)\n",
    "    \n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(fpr, tpr,label=\"ROC curve of class 1.0 (area = \"+str(roc_auc)+\")\")\n",
    "    plt.plot([0,1],[0,1],label=\"\",color=\"black\", linestyle='dashed')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC curves\")\n",
    "    plt.show()\n",
    "def binary(y):\n",
    "    y_out=[]\n",
    "    for i in y:\n",
    "        if i<0.5:\n",
    "            y_out.append(0.0)\n",
    "        else:\n",
    "            y_out.append(1.0)\n",
    "    return y_out\n",
    "def take_data_preprocess(filename,col):\n",
    "    x=pd.read_csv(filename)\n",
    "    x=x[x[col]!=-1.0]\n",
    "    y=np.array(x[col])\n",
    "    y=binary(y)\n",
    "    x=x.drop([\"Unnamed: 0\"],axis=1)\n",
    "    y=np.array(y).reshape(len(y)  ,)\n",
    "    y_1=np.where(y==0.0)[0]\n",
    "    y_2=np.where(y==1.0)[0]\n",
    "    index=np.random.choice(y_1,len(y_2), replace=False)\n",
    "    index=np.concatenate((index, y_2), axis=0)\n",
    "    x_32=x[[ 'AA_x', 'AT_x', 'AG_x', 'AC_x',\n",
    "       'TA_x', 'TT_x', 'TG_x', 'TC_x', 'GA_x', 'GT_x', 'GG_x', 'GC_x', 'CA_x',\n",
    "       'CT_x', 'CG_x', 'CC_x', 'AA_y', 'AT_y', 'AG_y', 'AC_y', 'TA_y', 'TT_y',\n",
    "       'TG_y', 'TC_y', 'GA_y', 'GT_y', 'GG_y', 'GC_y', 'CA_y', 'CT_y', 'CG_y',\n",
    "       'CC_y']]\n",
    "    x_32_norm=np.array(normalize(np.array(x_32)))\n",
    "    x, y = shuffle(x_32_norm[index], y[index], random_state=0)\n",
    "    return x,y\n",
    "results_cancer=[]\n",
    "j=0\n",
    "for filename in filenames:\n",
    "    \n",
    "    x,y=take_data_preprocess(filename,cancer_types[j])\n",
    "    print(filename,len(x))\n",
    "    x=StandardScaler().fit_transform(x)\n",
    "    \n",
    "    \n",
    "    originalclass = []\n",
    "    predictedclass = []\n",
    "    predictedprob = []\n",
    "    featureimportances = []\n",
    "\n",
    "    outer_cv = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "    nested_score = cross_val_score(clf, X=x, y=y, cv=outer_cv, scoring= make_scorer(classification_report_with_f1_score))\n",
    "    \n",
    "    for train, test in outer_cv.split(x,y):\n",
    "            clf = RandomForestClassifier(class_weight='balanced', max_depth=20 ,n_estimators=800, criterion='entropy')\n",
    "            clf.fit(x[train], y[train])\n",
    "            \n",
    "            originalclass.extend(y[test])\n",
    "            predictedclass.extend(clf.predict(x[test]))\n",
    "            predictedprob.extend(clf.predict_proba(x[test]))\n",
    "            featureimportances.append(clf.feature_importances_)\n",
    "            \n",
    "            \n",
    "    \n",
    "    results_cancer.append([originalclass,predictedclass,predictedprob,featureimportances])\n",
    "    \n",
    "    j+=1\n",
    "    \n",
    "    print(classification_report(originalclass, predictedclass))\n",
    "human_data=pd.read_csv(\"/project/ReadStatistics/MethylationAnalysis/Data/FinalFile_20_datasets_mean.csv\")\n",
    "def get_results(filename,col=\"categorize\"):\n",
    "    results=[]\n",
    "\n",
    "    x,y=take_data_preprocess(filename,col)\n",
    "    x=StandardScaler().fit_transform(x)\n",
    "\n",
    "\n",
    "    originalclass = []\n",
    "    predictedclass = []\n",
    "    predictedprob = []\n",
    "    featureimportances = []\n",
    "\n",
    "    outer_cv = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "    for train, test in outer_cv.split(x,y):\n",
    "            clf = RandomForestClassifier(class_weight='balanced', max_depth=20 , n_estimators=600) \n",
    "            clf.fit(x[train], y[train])\n",
    "\n",
    "            originalclass.extend(y[test])\n",
    "            predictedclass.extend(clf.predict(x[test]))\n",
    "            predictedprob.extend(clf.predict_proba(x[test]))\n",
    "            featureimportances.append(clf.feature_importances_)\n",
    "\n",
    "\n",
    "\n",
    "    results.append([originalclass,predictedclass,predictedprob,featureimportances])\n",
    "    return results\n",
    "filename_human20 = \"/project/ReadStatistics/MethylationAnalysis/Data/FinalFile_20_datasets_mean.csv\"\n",
    "filename_human10 = \"/project/ReadStatistics/MethylationAnalysis/Data/FinalFile_10_datasets_mean.csv\"\n",
    "results_human20=get_results(filename_human20)\n",
    "results_human10=get_results(filename_human10)\n",
    "samples,accuracy_blood\n",
    "len(file_sizes_blood)\n",
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "# j=0\n",
    "# for i in results_cancer:\n",
    "#     acc=accuracy_score(i[0],i[1])\n",
    "#     plt.scatter(file_sizes[j],acc,label=cancer_types[j],s=200)\n",
    "#     j+=1\n",
    "\n",
    "j=0\n",
    "for i in accuracy_blood[:len(samples)]:\n",
    "    plt.scatter(file_sizes_blood[j],i,label=samples[j],s=300)\n",
    "    j+=1\n",
    "\n",
    "\n",
    "acc=accuracy_score(results_human20[0],results_human20[1])\n",
    "plt.scatter(816687234*20,acc,label=\"HUMAN BLOOD 20 SAMPLES\",s=300,color=\"black\")\n",
    "\n",
    "acc=accuracy_score(results_human10[0],results_human10[1])\n",
    "plt.scatter(816687234*10,acc,label=\"HUMAN BLOOD 10 SAMPLES\",s=300,color=\"black\")\n",
    "    \n",
    "plt.xlabel(\"Number of reads\",fontsize=20)\n",
    "plt.ylabel(\"Test accuracy\",fontsize=20)\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(title=\"Sample name\",fontsize=15,title_fontsize=15, loc='lower right')\n",
    "\n",
    "plt.savefig(\"Figures/test_acc_vs_no_reads.pdf\",dpi=1000)\n",
    "\n",
    "plt.show()\n",
    "samples\n",
    "accuracy_blood = np.array(accuracy_blood)\n",
    "file_sizes_blood = np.array(file_sizes_blood)\n",
    "samples = np.array(samples)\n",
    "\n",
    "results_human20 = np.array([results_human20[0][0],results_human20[0][1]])\n",
    "results_human10 = np.array([results_human10[0][0],results_human10[0][1]])\n",
    "np.savez(\"Figures/test_acc_vs_no_reads_data.npz\", \n",
    "         accuracy_blood=np.array(accuracy_blood, dtype=object),  \n",
    "         file_sizes_blood=np.array(file_sizes_blood, dtype=object),  \n",
    "         samples=np.array(samples, dtype=object),  \n",
    "         acc_human20=results_human20,  \n",
    "         acc_human10=results_human10)\n",
    "features=[]\n",
    "for i in \"ATGC\":\n",
    "    for j in \"ATGC\":\n",
    "        features.append(i+j)\n",
    "\n",
    "features_sort=[]\n",
    "for i in \"ACGT\":\n",
    "    for j in \"ACGT\":\n",
    "        features_sort.append(i+j)\n",
    "    \n",
    "index_sorted=[]\n",
    "for i in range(16):\n",
    "    for j in range(16):\n",
    "        if features[i]==features_sort[j]:\n",
    "            index_sorted.append(j) \n",
    "\n",
    "\n",
    "# Train a model on the human blood data 20 samples and get the feature importances\n",
    "filename_human20 = \"/project/ReadStatistics/MethylationAnalysis/Data/FinalFile_20_datasets_mean.csv\"\n",
    "\n",
    "x,y=take_data_preprocess(filename_human20,\"categorize\")\n",
    "x=StandardScaler().fit_transform(x)\n",
    "\n",
    "clf = RandomForestClassifier(class_weight='balanced', max_depth=20 ,n_estimators=800, criterion='entropy')\n",
    "clf.fit(x,y)\n",
    "\n",
    "feature_importances = clf.feature_importances_\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(np.arange(0,16),feature_importances[index_sorted],color=\"blue\",label=\"Feature importances\")\n",
    "plt.xticks(np.arange(0,16)+5*0.1,np.array(features)[index_sorted],fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(\"\\nFeatures\",fontsize=20)\n",
    "plt.ylabel(\"\\nFeature importances\",fontsize=20)\n",
    "plt.legend(bbox_to_anchor=(1.0, 1.0),title=\"Sample names\",fontsize=15,title_fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(\"Figures/feature_importances.pdf\",dpi=800)\n",
    "\n",
    "plt.show()\n",
    "features\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort feature importances and corresponding feature names\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]  # Sort in descending order\n",
    "sorted_importances = feature_importances[sorted_idx]\n",
    "sorted_features = np.array(features)[sorted_idx]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))  # Increase width for better visibility\n",
    "plt.bar(np.arange(len(sorted_features)), sorted_importances, color=\"royalblue\", alpha=0.8)\n",
    "\n",
    "# Labels\n",
    "plt.xticks(np.arange(len(sorted_features)), sorted_features, fontsize=16, rotation=45, ha=\"right\")\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"Features\", fontsize=18)\n",
    "plt.ylabel(\"Feature Importance\", fontsize=18)\n",
    "plt.title(\"Feature Importances\", fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "# Save plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Figures/feature_importances.pdf\", dpi=800, bbox_inches=\"tight\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# ✅ Save necessary data for future use\n",
    "np.savez(\"Figures/feature_importances_data.npz\",\n",
    "         feature_importances=sorted_importances,\n",
    "         features=sorted_features)\n",
    "plt.figure(figsize=(10,6))\n",
    "j=0\n",
    "for i in results:\n",
    "    plt.bar( np.arange(0,32,2)+j*0.1,np.mean(i[3],axis=0)[index_sorted],label=cancer_types[j], width = 0.05)\n",
    "    j+=1\n",
    "    \n",
    "plt.bar( np.arange(0,32,2)+j*0.1,np.mean(results_human20[0][3],axis=0)[index_sorted],label=\"HUMAN BLOOD 20 SAMPLES\", width = 0.05)\n",
    "\n",
    "plt.xticks(np.arange(0,32,2)+5*0.1,np.array(features)[index_sorted],fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(\"\\nFeatures\",fontsize=20)\n",
    "plt.ylabel(\"\\nFeature importances\",fontsize=20)\n",
    "plt.legend(bbox_to_anchor=(1.0, 1.0),title=\"Sample names\",fontsize=15,title_fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(\"Figures/feature_importances.pdf\",dpi=800)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Train a model on the human blood data 20 samples and test on the cancer data with thresholding \n",
    "\n",
    "x,y=take_data_preprocess(filename_human20,\"categorize\")\n",
    "x=StandardScaler().fit_transform(x)\n",
    "\n",
    "clf = RandomForestClassifier(class_weight='balanced', max_depth=20 ,n_estimators=800, criterion='entropy')\n",
    "clf.fit(x,y)\n",
    "\n",
    "accuracy_cancer=[]\n",
    "j=0\n",
    "\n",
    "for filename in filenames:\n",
    "    \n",
    "    \n",
    "    x,y=take_data_preprocess(filename,cancer_types[j])\n",
    "    x=StandardScaler().fit_transform(x)\n",
    "    \n",
    "    predictedclass = clf.predict(x) \n",
    "    \n",
    "    originalclass = binary(y)\n",
    "    \n",
    "    accuracy_cancer.append(sk.metrics.accuracy_score(originalclass, predictedclass))\n",
    "    \n",
    "    print(classification_report(originalclass, predictedclass))\n",
    "    \n",
    "    j+=1\n",
    "accuracy_cancer\n",
    "filenames=[]\n",
    "for i in os.listdir(\"Data/\"):\n",
    "    if len(i.strip('.csv'))==7:\n",
    "        filenames.append(\"Data/\"+i)\n",
    "filenames\n",
    "\n",
    "np.mean(accuracy_cancer),np.std(accuracy_cancer),np.mean(accuracy_blood),np.std(accuracy_blood)\n",
    "# load all the data and make plots \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
